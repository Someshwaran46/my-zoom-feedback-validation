# ğŸ¤– My Zoom: A Transformer-Based Model for Contextual Feedback Validation

## ğŸ“š Overview

This project presents a contextual NLP model designed to validate whether user feedback aligns with a predefined dropdown reason. Leveraging transformer models like BERT and RoBERTa, it ensures meaningful and structured feedback in EdTech systems.

---

## ğŸ¯ Problem Statement

Modern EdTech platforms gather massive amounts of user feedback. However, many responses are misaligned with the intended category or reason.  
This project addresses:
- **Labeling feedback as aligned (1) or not aligned (0) with a selected reason**
- **Improving feedback quality and automating moderation**

---

## ğŸ’¼ Business Use Cases

- âœ… **Feedback Moderation** in EdTech apps
- ğŸ” **Survey Quality Control** through classification
- ğŸ“Š **Analytical Insights** based on relevant user responses
- ğŸ¤– **Smart Automation** for customer feedback filtering

---

## ğŸ§  Skills Gained

- Text Preprocessing & Data Augmentation  
- Transformers (BERT, RoBERTa)  
- Text Pair Modeling for NLP  
- Binary Classification with Transformers  
- Model Evaluation & Deployment (Gradio + Hugging Face Spaces)

---

## ğŸ“¦ Dataset Details

- **Format:** CSV (Tabular)
- **Columns:**
  - `text`: User feedback  
  - `reason`: Dropdown reason selected by the user  
  - `label`: Target variable (`1` if aligned, `0` if not)

- **Preprocessing Steps:**
  - Text cleaning (punctuation, stopwords, typos)
  - Data augmentation (for class 0)
  - Tokenization using transformer tokenizer

---

## ğŸš€ Project Workflow

1. **Data Preparation**
   - Cleaning and balancing the dataset
   - Augmenting negative class using paraphrasing or mismatch generation

2. **Model Development**
   - Input: text + reason (as pairs)
   - Model: BERT or RoBERTa fine-tuned for binary classification

3. **Evaluation**
   - Metrics: Accuracy, Precision, Recall, F1-score
   - Tools: Confusion Matrix, classification report

4. **Deployment**
   - Built UI using Gradio
   - Hosted on Hugging Face Spaces

---

## ğŸ§ª Evaluation Metrics

| Metric        | Purpose                                   |
|---------------|--------------------------------------------|
| Accuracy      | Overall correctness                       |
| Precision     | True relevance of predicted label 1        |
| Recall        | Modelâ€™s ability to capture all true 1s     |
| F1-Score      | Balance between Precision & Recall         |
| Confusion Matrix | Visual classification effectiveness    |

---

## ğŸŒ Deployment

- **UI Framework**: Gradio  
- **Hosting Platform**: Hugging Face Spaces

---
## ğŸ“‚ Repository Structure
```bash
Project/
â”œâ”€â”€ My_Zoom/
â”‚   â”œâ”€â”€ Dataset/
â”‚   â”‚   â”œâ”€â”€ evaluation.xlsx
â”‚   â”‚   â”œâ”€â”€ train.xlsx
â”‚   â”‚   â””â”€â”€ semantic_augmented_balanced_dataset.xlsx
â”‚   â””â”€â”€ My_Zoom.ipynb
â””â”€â”€ Screenshots for reference/
â”‚   â”œâ”€â”€ Feedback is accepted.png
â”‚   â””â”€â”€ Feedback is not accepted.png                
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
---

## ğŸ”§ How to Run
#### Clone the repository
```bash
git clone https://github.com/Someshwaran46/my-zoom-feedback-validation.git
cd my-zoom-feedback-validation
```
#### Install dependencies
```bash
pip install -r requirements.txt
```
#### Run the Gradio app
```bash
python app/gradio_app.py
```
---
## ğŸ“¬ Feedback

- Feel free to open issues or submit pull requests! Improvements, and suggestions are always welcome ğŸ™Œ.
- For clarifications drop an email to somesh4602@gmail.com.
---

